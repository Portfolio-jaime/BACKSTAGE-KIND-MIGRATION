# üìù Sesi√≥n Actual - Octubre 11, 2025

**√öltima actualizaci√≥n**: 23:00 hrs
**Status**: ‚úÖ Sistema funcionando correctamente

---

## üéØ Estado Actual del Proyecto

### ArgoCD Applications (4 total)

```bash
kubectl get application -n argocd
```

| Aplicaci√≥n | Sync Status | Health Status | Descripci√≥n |
|------------|-------------|---------------|-------------|
| **backstage** | ‚úÖ Synced | ‚ù§Ô∏è Healthy | Aplicaci√≥n principal + Ingress |
| **kube-prometheus-stack** | ‚úÖ Synced | ‚ù§Ô∏è Healthy | Prometheus + Grafana + AlertManager |
| **gitops1** | ‚úÖ Synced | ‚ù§Ô∏è Healthy | Otra aplicaci√≥n |
| **python-app-1** | ‚úÖ Synced | ‚ù§Ô∏è Healthy | Otra aplicaci√≥n |

---

## üì¶ Componentes Desplegados

### Namespace: backstage

```bash
kubectl get all -n backstage
```

- ‚úÖ **Backstage** (Deployment) - Developer Portal
- ‚úÖ **PostgreSQL** (StatefulSet) - Base de datos 17.6.0
  - Storage: 8Gi PVC
  - Desplegado con Helm (NO gestionado por ArgoCD)
  - Release name: `psql`
- ‚úÖ **Ingress** - http://backstage.kind.local
  - Incluido en el chart de Backstage

### Namespace: monitoring

```bash
kubectl get pods -n monitoring
```

- ‚úÖ **Prometheus** (StatefulSet)
  - Storage: 5Gi (gestionado autom√°ticamente)
  - M√©tricas: Todas funcionando
- ‚úÖ **Grafana** (Deployment)
  - Storage: 2Gi PVC
  - GitHub OAuth: ‚úÖ Configurado y funcionando
  - Secret: `grafana-github-oauth`
- ‚úÖ **AlertManager** (StatefulSet)
  - Storage: 1Gi
- ‚úÖ **Prometheus Operator** (Deployment)
- ‚úÖ **Node Exporter** (DaemonSet)
- ‚úÖ **Kube State Metrics** (Deployment)

### Alertas y Dashboards

```bash
kubectl get prometheusrule -n monitoring | grep backstage
```

- ‚úÖ **9 Alertas de Backstage** (PrometheusRule)
  - Aplicadas manualmente con `kubectl apply`
  - Archivo: `helm-charts/monitoring/templates/backstage-alerts.yaml`
  - NO gestionadas por ArgoCD (para evitar conflictos)

---

## üöÄ Lo que Funciona

### 1. Monitoring Stack Completo ‚úÖ

**Gestionado por ArgoCD:**
- Application: `kube-prometheus-stack`
- Source: https://prometheus-community.github.io/helm-charts
- Chart version: 65.0.0
- **Values**: `helm-charts/monitoring/values.yaml` (desde el repo)

**Configuraci√≥n activa:**
- GitHub OAuth para Grafana
- Persistent storage (5Gi + 2Gi + 1Gi)
- Targets DOWN en Kind documentados como normales
- Alertas deshabilitadas para componentes no disponibles (etcd, scheduler, etc.)

### 2. PostgreSQL Funcional ‚úÖ

**NO gestionado por ArgoCD** (para evitar conflictos):
- Desplegado con Helm directamente
- Release: `psql`
- Chart: Bitnami PostgreSQL 16.7.27
- Version: 17.6.0
- Storage: 8Gi PVC

```bash
helm list -n backstage
# NAME	NAMESPACE	REVISION	STATUS  	CHART             	APP VERSION
# psql	backstage	1       	deployed	postgresql-16.7.27	17.6.0
```

### 3. Backstage con GitOps ‚úÖ

**Gestionado por ArgoCD:**
- Application: `backstage`
- Incluye Ingress autom√°ticamente
- Conectado a PostgreSQL
- Image Updater activo

---

## üîß Configuraciones Importantes

### Secrets Creados

```bash
# Grafana GitHub OAuth (monitoring namespace)
kubectl get secret grafana-github-oauth -n monitoring
# Contenido:
# - GF_AUTH_GITHUB_CLIENT_ID: Ov23liX98Qe1ectC1zdj
# - GF_AUTH_GITHUB_CLIENT_SECRET: 3133588a686087d188d1b85c145cfc562a4a9a69

# PostgreSQL (backstage namespace)
kubectl get secret psql-postgresql -n backstage
# Password: backstage

# Backstage (backstage namespace)
kubectl get secret backstage-secrets -n backstage
```

### GitHub OAuth App

**Usado por ArgoCD y Grafana:**
- Client ID: `Ov23liX98Qe1ectC1zdj`
- Client Secret: `3133588a686087d188d1b85c145cfc562a4a9a69`
- Organization: `Portfolio-jaime`

**Callbacks configurados:**
- ArgoCD: `https://argocd.kind.local/api/dex/callback`
- Grafana: `http://grafana.kind.local/login/github`

---

## üìÅ Archivos Importantes

### En el Repositorio

```
backstage-kind-migration/
‚îú‚îÄ‚îÄ argocd/
‚îÇ   ‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ postgresql-application.yaml      # NO APLICADO (conflictos)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingress-application.yaml         # NO APLICADO (ya existe)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ monitoring-config-application.yaml # NO APLICADO (errores)
‚îÇ   ‚îú‚îÄ‚îÄ argocd-cm.yaml                       # ‚úÖ ArgoCD config (OAuth)
‚îÇ   ‚îú‚îÄ‚îÄ argocd-rbac-cm.yaml                  # ‚úÖ RBAC (jaimehenao8126 admin)
‚îÇ   ‚îî‚îÄ‚îÄ README.md                            # Gu√≠a de ArgoCD
‚îÇ
‚îú‚îÄ‚îÄ helm-charts/
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ values.yaml                      # ‚úÖ USADO POR ARGOCD
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md                        # Gu√≠a de monitoring
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ templates/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ backstage-alerts.yaml        # ‚úÖ Aplicado manualmente
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ backstage-dashboard.json     # Dashboard (no usado)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ postgresql/                          # NO USADO (PostgreSQL con Helm)
‚îÇ   ‚îî‚îÄ‚îÄ ingress/                             # NO USADO (incluido en Backstage)
‚îÇ
‚îî‚îÄ‚îÄ docs/
    ‚îú‚îÄ‚îÄ MONITORING_SETUP_GUIDE.md            # ‚úÖ Gu√≠a completa
    ‚îú‚îÄ‚îÄ MONITORING_IMPLEMENTATION.md         # ‚úÖ GitOps implementation
    ‚îú‚îÄ‚îÄ ARGOCD_CONFIGURATION.md              # ‚úÖ ArgoCD setup
    ‚îî‚îÄ‚îÄ SESION_ACTUAL.md                     # üìç ESTE ARCHIVO
```

---

## üé® Acceso a Servicios

### Port Forward

```bash
# Backstage
kubectl port-forward -n backstage svc/backstage 7007:80
# http://localhost:7007

# ArgoCD
kubectl port-forward -n argocd svc/argocd-server 8080:443
# https://localhost:8080
# User: GitHub OAuth o admin/password

# Grafana
kubectl port-forward -n monitoring svc/kube-prometheus-stack-grafana 3000:80
# http://localhost:3000
# User: GitHub OAuth o admin/admin123

# Prometheus
kubectl port-forward -n monitoring svc/prometheus-prometheus 9090:9090
# http://localhost:9090

# AlertManager
kubectl port-forward -n monitoring svc/prometheus-alertmanager 9093:9093
# http://localhost:9093
```

### Con Ingress (agregar a /etc/hosts)

```bash
echo "127.0.0.1 backstage.kind.local argocd.kind.local grafana.kind.local prometheus.kind.local" | sudo tee -a /etc/hosts
```

---

## ‚ö†Ô∏è Problemas Encontrados y Soluciones

### 1. PostgreSQL Application - CONFLICTO ‚ùå

**Problema:**
- PostgreSQL ya est√° desplegado con Helm
- ArgoCD intentaba gestionar un release existente
- Status: Unknown/OutOfSync

**Soluci√≥n aplicada:**
- Eliminamos la application de ArgoCD
- Dejamos PostgreSQL gestionado con Helm directamente
- **NO intentar agregar PostgreSQL a ArgoCD**

### 2. Ingress Duplicado - CONFLICTO ‚ùå

**Problema:**
- Creamos application de ingress en ArgoCD
- Pero el ingress ya existe en el chart de Backstage

**Soluci√≥n aplicada:**
- Eliminamos la application `backstage-ingress`
- El ingress est√° incluido en el chart de Backstage

### 3. Monitoring Config - ERROR ‚ùå

**Problema:**
- `backstage-monitoring-config` application con errores
- Dashboard JSON ten√≠a sintaxis de Helm incorrecta
- Error: `function "pod" not defined`

**Soluci√≥n aplicada:**
- Eliminamos la application de ArgoCD
- Aplicamos alertas manualmente con kubectl
- Dashboard no se usa por ahora

### 4. Grafana CreateContainerConfigError - RESUELTO ‚úÖ

**Problema:**
- Grafana en status `CreateContainerConfigError`
- Secret `grafana-github-oauth` no exist√≠a

**Soluci√≥n aplicada:**
```bash
kubectl create secret generic grafana-github-oauth -n monitoring \
  --from-literal=GF_AUTH_GITHUB_CLIENT_ID='Ov23liX98Qe1ectC1zdj' \
  --from-literal=GF_AUTH_GITHUB_CLIENT_SECRET='3133588a686087d188d1b85c145cfc562a4a9a69'
```

---

## üîÑ Flujo GitOps Actual

### Para Actualizar Monitoring

1. Modificar `helm-charts/monitoring/values.yaml`
2. Commit y push a GitHub
3. ArgoCD sincroniza autom√°ticamente (cada 3 min)

```bash
vim helm-charts/monitoring/values.yaml
git add helm-charts/monitoring/values.yaml
git commit -m "feat: actualizar configuraci√≥n de monitoring"
git push origin main

# ArgoCD aplicar√° cambios autom√°ticamente
```

### Para Ver Estado

```bash
# Ver todas las aplicaciones
kubectl get application -n argocd

# Ver detalles de monitoring
kubectl describe application kube-prometheus-stack -n argocd

# Ver pods
kubectl get pods -n monitoring
kubectl get pods -n backstage

# Ver PVCs (storage)
kubectl get pvc -n monitoring
kubectl get pvc -n backstage
```

---

## üìä M√©tricas y Alertas

### Alertas Configuradas (9 total)

```bash
kubectl get prometheusrule backstage-alerts -n monitoring
```

| Alerta | Severidad | Condici√≥n |
|--------|-----------|-----------|
| BackstagePodDown | Critical | Pod no Running > 5min |
| BackstagePodCrashLooping | Warning | Restarts detectados |
| BackstageHighMemoryUsage | Warning | Memoria > 85% por 10min |
| BackstageHighCPUUsage | Warning | CPU > 85% por 10min |
| BackstagePodNotReady | Warning | Pod not ready > 5min |
| PostgreSQLDown | Critical | PostgreSQL down > 2min |
| PostgreSQLHighMemoryUsage | Warning | PostgreSQL mem > 90% |
| BackstageNamespaceQuotaExceeded | Warning | Quota > 90% |

**Ver alertas activas:**
```bash
# En Prometheus UI
kubectl port-forward -n monitoring svc/prometheus-prometheus 9090:9090
# http://localhost:9090/alerts
```

### Targets de Prometheus

**Targets UP (funcionando):** ‚úÖ
- Grafana
- Kube State Metrics
- Node Exporter
- AlertManager
- API Server
- CoreDNS
- Kubelet
- Prometheus Operator

**Targets DOWN (normal en Kind):** ‚ö†Ô∏è
- kube-controller-manager (puerto 10257)
- kube-scheduler (puerto 10259)
- kube-proxy (puerto 10249)
- etcd (puerto 2381)

**Raz√≥n:** Kind no expone estos puertos por seguridad. **Es comportamiento esperado**.

---

## üöÄ Pr√≥ximos Pasos (Para Ma√±ana)

### 1. Opcional: Dashboard de Backstage en Grafana

- Fix del JSON del dashboard (remover sintaxis de Helm)
- Importar manualmente en Grafana UI

### 2. M√©tricas de Backstage

- Instalar plugin `@backstage/plugin-prometheus`
- Configurar endpoint `/metrics` en Backstage
- Crear ServiceMonitor

### 3. Notificaciones de AlertManager

- Configurar Slack webhook
- Actualizar AlertManager config

### 4. Documentaci√≥n Final

- Crear diagrama de arquitectura
- Quick Start guide completo
- Video o screenshots de la UI

---

## üìù Comandos √ötiles

### Verificaci√≥n R√°pida

```bash
# Estado de ArgoCD
kubectl get application -n argocd

# Estado de Monitoring
kubectl get pods -n monitoring
kubectl get pvc -n monitoring

# Estado de Backstage
kubectl get pods -n backstage
kubectl get pvc -n backstage

# Ver alertas
kubectl get prometheusrule -n monitoring

# Ver servicemonitors
kubectl get servicemonitor -A
```

### Logs

```bash
# Grafana
kubectl logs -n monitoring deployment/kube-prometheus-stack-grafana -f

# Prometheus
kubectl logs -n monitoring prometheus-prometheus-prometheus-0 -c prometheus -f

# Backstage
kubectl logs -n backstage -l app=backstage -f

# PostgreSQL
kubectl logs -n backstage psql-postgresql-0 -f
```

### Troubleshooting

```bash
# Ver eventos recientes
kubectl get events -n monitoring --sort-by='.lastTimestamp' | head -20
kubectl get events -n backstage --sort-by='.lastTimestamp' | head -20

# Describir pod con problemas
kubectl describe pod <pod-name> -n <namespace>

# Reiniciar ArgoCD controller
kubectl delete pod -n argocd -l app.kubernetes.io/name=argocd-application-controller

# Forzar sync de una app
kubectl patch application <app-name> -n argocd --type merge \
  -p '{"operation": {"initiatedBy": {"username": "admin"}, "sync": {"revision": "HEAD"}}}'
```

---

## üìö Documentaci√≥n Relacionada

1. **[README.md](../README.md)** - Documentaci√≥n principal completa
2. **[argocd/README.md](../argocd/README.md)** - Gu√≠a de ArgoCD App of Apps
3. **[helm-charts/monitoring/README.md](../helm-charts/monitoring/README.md)** - Gu√≠a de monitoring
4. **[helm-charts/postgresql/README.md](../helm-charts/postgresql/README.md)** - Gu√≠a de PostgreSQL
5. **[docs/MONITORING_SETUP_GUIDE.md](MONITORING_SETUP_GUIDE.md)** - Setup de monitoring
6. **[docs/MONITORING_IMPLEMENTATION.md](MONITORING_IMPLEMENTATION.md)** - GitOps implementation
7. **[docs/ARGOCD_CONFIGURATION.md](ARGOCD_CONFIGURATION.md)** - Config de ArgoCD

---

## ‚úÖ Checklist de Funcionalidad

- [x] Backstage desplegado y funcionando
- [x] PostgreSQL con persistent storage (8Gi)
- [x] Monitoring stack completo (Prometheus + Grafana + AlertManager)
- [x] Persistent storage para monitoring (5Gi + 2Gi + 1Gi)
- [x] GitHub OAuth para Grafana
- [x] 9 Alertas configuradas
- [x] Targets de Prometheus funcionando
- [x] ArgoCD gestionando Backstage y Monitoring
- [x] GitOps workflow funcionando
- [x] Documentaci√≥n completa
- [ ] Dashboard de Backstage en Grafana (pendiente)
- [ ] M√©tricas de Backstage (pendiente)
- [ ] Notificaciones de Slack (pendiente)

---

**Maintainer:** Jaime Henao <jaime.andres.henao.arbelaez@ba.com>
**Repository:** https://github.com/Portfolio-jaime/backstage-kind-migration
**√öltima sesi√≥n:** Octubre 11, 2025 - 23:00 hrs

**Estado:** ‚úÖ Todo funcionando sin errores
