# üìö Gu√≠a Completa de Implementaci√≥n - Platform Monitoring Stack

**Fecha**: Octubre 6, 2025
**Proyecto**: Backstage Platform on Kind
**Autor**: Platform Engineering Team

---

## üìë √çndice

1. [Resumen Ejecutivo](#resumen-ejecutivo)
2. [Arquitectura Implementada](#arquitectura-implementada)
3. [Componentes Desplegados](#componentes-desplegados)
4. [Pasos de Implementaci√≥n](#pasos-de-implementaci√≥n)
5. [Configuraci√≥n de Backstage Pages](#configuraci√≥n-de-backstage-pages)
6. [Cat√°logo de Servicios](#cat√°logo-de-servicios)
7. [Acceso y Credenciales](#acceso-y-credenciales)
8. [Troubleshooting](#troubleshooting)
9. [Anexos](#anexos)

---

## üìä Resumen Ejecutivo

### ‚úÖ Objetivo Cumplido

Se implement√≥ exitosamente un **Developer Portal completo** con:
- ‚úÖ Backstage como portal central
- ‚úÖ Stack de monitoring (Prometheus + Grafana)
- ‚úÖ GitOps con ArgoCD
- ‚úÖ Gesti√≥n de alertas (AlertManager)
- ‚úÖ Cat√°logo unificado de servicios
- ‚úÖ Documentaci√≥n exhaustiva

### üéØ Resultados

| Componente | Estado | URL | Namespace |
|------------|--------|-----|-----------|
| Backstage | ‚úÖ Running | http://backstage.kind.local | backstage |
| Prometheus | ‚úÖ Running | http://prometheus.kind.local | monitoring |
| Grafana | ‚úÖ Running | http://grafana.kind.local | monitoring |
| ArgoCD | ‚úÖ Running | http://argocd.kind.local | argocd |
| AlertManager | ‚úÖ Running | http://alertmanager.kind.local | monitoring |

---

## üèóÔ∏è Arquitectura Implementada

### Diagrama de Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Usuario / Desarrollador                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      /etc/hosts (DNS Local)                  ‚îÇ
‚îÇ  127.0.0.1 backstage.kind.local                             ‚îÇ
‚îÇ  127.0.0.1 prometheus.kind.local                            ‚îÇ
‚îÇ  127.0.0.1 grafana.kind.local                               ‚îÇ
‚îÇ  127.0.0.1 argocd.kind.local                                ‚îÇ
‚îÇ  127.0.0.1 alertmanager.kind.local                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              NGINX Ingress Controller (Port 80)              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇBackstage ‚îÇPrometheus‚îÇ Grafana  ‚îÇ ArgoCD   ‚îÇAlertMgr  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ Ingress  ‚îÇ Ingress  ‚îÇ Ingress  ‚îÇ Ingress  ‚îÇ Ingress  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚ñº                  ‚ñº                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Backstage NS  ‚îÇ ‚îÇ Monitoring NS‚îÇ ‚îÇ  ArgoCD NS   ‚îÇ
‚îÇ                 ‚îÇ ‚îÇ              ‚îÇ ‚îÇ              ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ ‚îÇ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ Backstage   ‚îÇ ‚îÇ ‚îÇ‚îÇPrometheus ‚îÇ‚îÇ ‚îÇ‚îÇArgoCD Srv ‚îÇ ‚îÇ
‚îÇ ‚îÇ Deployment  ‚îÇ ‚îÇ ‚îÇ‚îÇStatefulSet‚îÇ‚îÇ ‚îÇ‚îÇDeployment ‚îÇ ‚îÇ
‚îÇ ‚îÇ (1 replica) ‚îÇ ‚îÇ ‚îÇ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ ‚îÇ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ ‚îÇ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ‚îÇ Grafana   ‚îÇ‚îÇ ‚îÇ‚îÇRepo Server‚îÇ ‚îÇ
‚îÇ ‚îÇ PostgreSQL  ‚îÇ ‚îÇ ‚îÇ‚îÇDeployment ‚îÇ‚îÇ ‚îÇ‚îÇDeployment ‚îÇ ‚îÇ
‚îÇ ‚îÇ StatefulSet ‚îÇ ‚îÇ ‚îÇ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ ‚îÇ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ ‚îÇ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ‚îÇAlertMgr   ‚îÇ‚îÇ ‚îÇ‚îÇApp Ctrl   ‚îÇ ‚îÇ
‚îÇ ‚îÇ ConfigMap   ‚îÇ ‚îÇ ‚îÇ‚îÇStatefulSet‚îÇ‚îÇ ‚îÇ‚îÇStatefulSet‚îÇ ‚îÇ
‚îÇ ‚îÇ Secrets     ‚îÇ ‚îÇ ‚îÇ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ ‚îÇ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ ‚îÇ RBAC        ‚îÇ ‚îÇ ‚îÇ              ‚îÇ ‚îÇ              ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ              ‚îÇ ‚îÇ              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                  ‚îÇ                  ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ   Kind Kubernetes Cluster          ‚îÇ
         ‚îÇ   ‚Ä¢ 1 Control Plane Node           ‚îÇ
         ‚îÇ   ‚Ä¢ Docker Desktop Backend         ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flujo de Datos

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Applications ‚îÇ
‚îÇ    Pods      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ Expose /metrics
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Prometheus  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ AlertManager ‚îÇ‚îÄ‚îÄ> Notifications
‚îÇ   Scrape     ‚îÇ      ‚îÇ  (Alerts)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îÇ Query API (PromQL)
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Grafana    ‚îÇ
‚îÇ  Dashboards  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
   üë§ User

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Git Repo    ‚îÇ
‚îÇ  (Source)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ Sync
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   ArgoCD     ‚îÇ
‚îÇ Repo Server  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ Deploy
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Kubernetes  ‚îÇ
‚îÇ   Cluster    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Backstage   ‚îÇ
‚îÇ   Portal     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îú‚îÄ‚îÄ> Catalog (Components)
       ‚îú‚îÄ‚îÄ> TechDocs
       ‚îú‚îÄ‚îÄ> Software Templates
       ‚îî‚îÄ‚îÄ> External Links (to all services)
```

---

## üß© Componentes Desplegados

### 1. Backstage (Namespace: `backstage`)

#### Deployment
```yaml
Name: backstage
Replicas: 1 (laboratorio)
Image: jaimehenao8126/backstage-production:latest
Resources:
  Requests: 250m CPU, 512Mi RAM
  Limits: 1 CPU, 2Gi RAM
Ports: 7007 (http)
```

#### PostgreSQL
```yaml
Name: psql-postgresql
Type: StatefulSet
Replicas: 1
Image: postgresql:14
Port: 5432
Database: backstage
User: backstage
```

#### ConfigMaps
- `backstage-env-config`: Variables de entorno
- `backstage-enhanced-config`: Configuraci√≥n completa de Backstage
- `backstage-platform-catalog`: Cat√°logo de servicios de plataforma

#### Secrets
- `backstage-secrets`: Credenciales (GitHub, ArgoCD, PostgreSQL)
- `psql-postgresql`: Password de PostgreSQL

#### RBAC
- ServiceAccount: `backstage`
- ClusterRole: `backstage-read` (lectura de recursos K8s)
- ClusterRoleBinding: `backstage-read-binding`

#### Services
- `backstage`: ClusterIP en puerto 80

#### Ingress
- Host: `backstage.kind.local`
- Backend: `backstage:80`

---

### 2. Monitoring Stack (Namespace: `monitoring`)

#### Prometheus
```yaml
Name: prometheus-prometheus
Type: StatefulSet
Replicas: 1
Image: quay.io/prometheus/prometheus
Port: 9090
Storage: PVC
Retention: 15 days
```

**Configuraci√≥n**:
- Scrape interval: 30s
- Service discovery: Kubernetes
- Alert rules: Configured
- Remote write: Disabled (local)

#### Grafana
```yaml
Name: kube-prometheus-stack-grafana
Type: Deployment
Replicas: 1
Image: grafana/grafana
Port: 80
```

**Data Sources**:
- Prometheus (default)
- Kubernetes API

**Plugins Instalados**:
- Kubernetes
- Prometheus
- Pie Chart
- State Timeline

#### AlertManager
```yaml
Name: alertmanager-prometheus-alertmanager
Type: StatefulSet
Replicas: 1
Image: quay.io/prometheus/alertmanager
Port: 9093
```

#### Node Exporter
```yaml
Name: kube-prometheus-stack-prometheus-node-exporter
Type: DaemonSet
Image: quay.io/prometheus/node-exporter
Port: 9100
```

#### Kube State Metrics
```yaml
Name: kube-prometheus-stack-kube-state-metrics
Type: Deployment
Replicas: 1
Port: 8080
```

#### Ingresses
- `prometheus`: prometheus.kind.local ‚Üí prometheus-prometheus:9090
- `grafana`: grafana.kind.local ‚Üí kube-prometheus-stack-grafana:80
- `alertmanager`: alertmanager.kind.local ‚Üí prometheus-alertmanager:9093

---

### 3. ArgoCD (Namespace: `argocd`)

#### ArgoCD Server
```yaml
Name: argocd-server
Type: Deployment
Replicas: 1
Ports: 8080 (http), 8083 (https)
```

#### Repo Server
```yaml
Name: argocd-repo-server
Type: Deployment
Replicas: 1
Port: 8081
```

#### Application Controller
```yaml
Name: argocd-application-controller
Type: StatefulSet
Replicas: 1
```

#### Redis
```yaml
Name: argocd-redis
Type: Deployment
Replicas: 1
Port: 6379
```

#### Dex (SSO)
```yaml
Name: argocd-dex-server
Type: Deployment
Replicas: 1
Ports: 5556, 5557
```

#### Ingress
- Host: `argocd.kind.local`
- Backend: `argocd-server:443`
- Protocol: HTTPS (backend)

---

## üöÄ Pasos de Implementaci√≥n

### Fase 1: Preparaci√≥n del Cluster

#### 1.1 Crear Cluster Kind
```bash
kind create cluster --name kind

# Verificar
kubectl cluster-info
kubectl get nodes
```

#### 1.2 Instalar NGINX Ingress
```bash
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml

# Esperar a que est√© listo
kubectl wait --namespace ingress-nginx \
  --for=condition=ready pod \
  --selector=app.kubernetes.io/component=controller \
  --timeout=90s
```

---

### Fase 2: Desplegar Monitoring Stack

#### 2.1 Agregar Helm Repository
```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
```

#### 2.2 Instalar Kube-Prometheus-Stack
```bash
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --create-namespace \
  --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false \
  --set grafana.adminPassword=admin
```

#### 2.3 Verificar Instalaci√≥n
```bash
kubectl get pods -n monitoring
kubectl get svc -n monitoring
kubectl get statefulset -n monitoring
```

#### 2.4 Crear Ingresses
```bash
kubectl apply -f kubernetes/monitoring-ingresses.yaml

# Verificar
kubectl get ingress -n monitoring
```

**Archivo**: `kubernetes/monitoring-ingresses.yaml`
```yaml
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: prometheus
  namespace: monitoring
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
spec:
  ingressClassName: nginx
  rules:
  - host: prometheus.kind.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: prometheus-prometheus
            port:
              number: 9090
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: grafana
  namespace: monitoring
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
spec:
  ingressClassName: nginx
  rules:
  - host: grafana.kind.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: kube-prometheus-stack-grafana
            port:
              number: 80
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: alertmanager
  namespace: monitoring
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
spec:
  ingressClassName: nginx
  rules:
  - host: alertmanager.kind.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: prometheus-alertmanager
            port:
              number: 9093
```

---

### Fase 3: Desplegar ArgoCD

#### 3.1 Crear Namespace
```bash
kubectl create namespace argocd
```

#### 3.2 Instalar ArgoCD
```bash
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
```

#### 3.3 Esperar a que est√© listo
```bash
kubectl wait --for=condition=available --timeout=300s \
  deployment/argocd-server -n argocd
```

#### 3.4 Crear Ingress
```bash
kubectl apply -f kubernetes/argocd-ingress.yaml
```

**Archivo**: `kubernetes/argocd-ingress.yaml`
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: argocd-server
  namespace: argocd
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
    nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
spec:
  ingressClassName: nginx
  rules:
  - host: argocd.kind.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: argocd-server
            port:
              number: 443
```

#### 3.5 Obtener Password Inicial
```bash
kubectl -n argocd get secret argocd-initial-admin-secret \
  -o jsonpath="{.data.password}" | base64 -d && echo
```

---

### Fase 4: Desplegar Backstage

#### 4.1 Crear Namespace
```bash
kubectl apply -f kubernetes/namespace.yaml
```

**Archivo**: `kubernetes/namespace.yaml`
```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: backstage
  labels:
    name: backstage
```

#### 4.2 Crear Secrets
```bash
kubectl apply -f kubernetes/secrets.yaml
```

**Archivo**: `kubernetes/secrets.yaml`
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: backstage-secrets
  namespace: backstage
type: Opaque
stringData:
  # PostgreSQL
  POSTGRES_HOST: "psql-postgresql.backstage.svc.cluster.local"
  POSTGRES_PORT: "5432"
  POSTGRES_USER: "backstage"
  POSTGRES_PASSWORD: "backstage"
  POSTGRES_DB: "backstage"

  # GitHub
  GITHUB_TOKEN: "tu-token-aqui"
  AUTH_GITHUB_CLIENT_ID: "tu-client-id"
  AUTH_GITHUB_CLIENT_SECRET: "tu-client-secret"

  # ArgoCD
  ARGOCD_USERNAME: "admin"
  ARGOCD_PASSWORD: "password-argocd"
  ARGOCD_AUTH_TOKEN: "token-argocd"

  # Backend
  BACKEND_SECRET: "random-secret-key"
```

#### 4.3 Crear ConfigMap
```bash
kubectl apply -f kubernetes/configmap.yaml
```

**Archivo**: `kubernetes/configmap.yaml`
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: backstage-env-config
  namespace: backstage
data:
  POSTGRES_HOST: "psql-postgresql.backstage.svc.cluster.local"
  POSTGRES_PORT: "5432"
  POSTGRES_DB: "backstage"
  NODE_ENV: "production"
  LOG_LEVEL: "info"
  APP_BASE_URL: "http://backstage.kind.local"
  BACKEND_BASE_URL: "http://backstage.kind.local"
  CORS_ORIGIN: "http://backstage.kind.local"
```

#### 4.4 Crear RBAC
```bash
kubectl apply -f kubernetes/rbac.yaml
```

**Archivo**: `kubernetes/rbac.yaml`
```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: backstage
  namespace: backstage
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: backstage-read
rules:
  - apiGroups: [""]
    resources: ["pods", "services", "configmaps", "namespaces"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["apps"]
    resources: ["deployments", "replicasets", "statefulsets"]
    verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: backstage-read-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: backstage-read
subjects:
  - kind: ServiceAccount
    name: backstage
    namespace: backstage
```

#### 4.5 Desplegar PostgreSQL (gestionado por ArgoCD)

PostgreSQL ahora se despliega y gestiona a trav√©s de ArgoCD, utilizando el chart de Helm local ubicado en `helm-charts/postgresql` en este repositorio. Las credenciales se obtienen del secret `backstage-secrets`.

**No es necesario ejecutar comandos `helm install` directamente para PostgreSQL.** La sincronizaci√≥n la realiza ArgoCD autom√°ticamente al detectar los cambios en el repositorio.

#### 4.6 Crear Deployment
```bash
kubectl apply -f kubernetes/simple-deployment.yaml
```

**Archivo**: `kubernetes/simple-deployment.yaml`
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backstage
  namespace: backstage
spec:
  replicas: 1
  selector:
    matchLabels:
      app: backstage
  template:
    metadata:
      labels:
        app: backstage
    spec:
      serviceAccountName: backstage
      containers:
      - name: backstage
        image: jaimehenao8126/backstage-production:latest
        imagePullPolicy: IfNotPresent
        ports:
        - name: http
          containerPort: 7007
        env:
        - name: APP_CONFIG_app_baseUrl
          value: "http://backstage.kind.local"
        - name: APP_CONFIG_backend_baseUrl
          value: "http://backstage.kind.local"
        envFrom:
        - secretRef:
            name: backstage-secrets
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        volumeMounts:
        - name: app-config
          mountPath: /app/app-config.production.yaml
          subPath: app-config.yaml
        - name: users
          mountPath: /app/users.yaml
          subPath: users.yaml
        - name: platform-services
          mountPath: /app/catalog/platform-services.yaml
          subPath: platform-services.yaml
      volumes:
      - name: app-config
        configMap:
          name: backstage-enhanced-config
      - name: users
        configMap:
          name: backstage-enhanced-config
      - name: platform-services
        configMap:
          name: backstage-platform-catalog
```

#### 4.7 Crear Service
```bash
kubectl apply -f kubernetes/service.yaml
```

**Archivo**: `kubernetes/service.yaml`
```yaml
apiVersion: v1
kind: Service
metadata:
  name: backstage
  namespace: backstage
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 7007
    protocol: TCP
    name: http
  selector:
    app: backstage
```

#### 4.8 Crear Ingress
```bash
kubectl apply -f kubernetes/ingress.yaml
```

**Archivo**: `kubernetes/ingress.yaml`
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: backstage
  namespace: backstage
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
spec:
  ingressClassName: nginx
  rules:
  - host: backstage.kind.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: backstage
            port:
              number: 80
```

---

### Fase 5: Configurar DNS Local

#### 5.1 Editar /etc/hosts

**macOS/Linux**:
```bash
sudo nano /etc/hosts
```

**Windows**:
```
Notepad como Administrator
C:\Windows\System32\drivers\etc\hosts
```

#### 5.2 Agregar Entradas
```
127.0.0.1 backstage.kind.local
127.0.0.1 prometheus.kind.local
127.0.0.1 grafana.kind.local
127.0.0.1 argocd.kind.local
127.0.0.1 alertmanager.kind.local
```

---

### Fase 6: Configurar Cat√°logo de Backstage

#### 6.1 Crear Cat√°logo de Platform Services
```bash
kubectl create configmap backstage-platform-catalog \
  -n backstage \
  --from-file=platform-services.yaml=backstage-catalog/platform-services.yaml
```

**Archivo**: `backstage-catalog/platform-services.yaml`
```yaml
---
apiVersion: backstage.io/v1alpha1
kind: Component
metadata:
  name: prometheus
  title: Prometheus Monitoring
  description: Monitoring and alerting toolkit
  annotations:
    backstage.io/kubernetes-id: prometheus
    backstage.io/kubernetes-namespace: monitoring
  tags:
    - monitoring
    - prometheus
    - metrics
  links:
    - url: http://prometheus.kind.local
      title: Prometheus UI
      icon: dashboard
    - url: http://prometheus.kind.local/targets
      title: Targets
      icon: catalog
    - url: http://prometheus.kind.local/alerts
      title: Alerts
      icon: alert
spec:
  type: service
  lifecycle: production
  owner: platform-engineering
  system: monitoring
---
apiVersion: backstage.io/v1alpha1
kind: Component
metadata:
  name: grafana
  title: Grafana Dashboards
  description: Analytics and visualization platform
  annotations:
    backstage.io/kubernetes-id: grafana
    backstage.io/kubernetes-namespace: monitoring
  tags:
    - monitoring
    - grafana
    - visualization
  links:
    - url: http://grafana.kind.local
      title: Grafana UI
      icon: dashboard
    - url: http://grafana.kind.local/dashboards
      title: Dashboards
      icon: catalog
spec:
  type: service
  lifecycle: production
  owner: platform-engineering
  system: monitoring
---
apiVersion: backstage.io/v1alpha1
kind: Component
metadata:
  name: argocd
  title: ArgoCD GitOps
  description: Declarative GitOps CD tool
  annotations:
    backstage.io/kubernetes-id: argocd-server
    backstage.io/kubernetes-namespace: argocd
  tags:
    - gitops
    - argocd
    - deployment
  links:
    - url: http://argocd.kind.local
      title: ArgoCD Console
      icon: dashboard
    - url: http://argocd.kind.local/applications
      title: Applications
      icon: catalog
spec:
  type: service
  lifecycle: production
  owner: platform-engineering
  system: platform
---
apiVersion: backstage.io/v1alpha1
kind: System
metadata:
  name: monitoring
  title: Monitoring System
  description: Complete monitoring stack
spec:
  owner: platform-engineering
---
apiVersion: backstage.io/v1alpha1
kind: System
metadata:
  name: platform
  title: Platform Services
  description: Core platform services
spec:
  owner: platform-engineering
```

#### 6.2 Actualizar ConfigMap de Backstage

Agregar la ubicaci√≥n del cat√°logo en `backstage-enhanced-config`:

```yaml
catalog:
  locations:
    - type: file
      target: /app/catalog/platform-services.yaml
```

#### 6.3 Reiniciar Backstage
```bash
kubectl delete pod -n backstage -l app=backstage
```

---

## üé® Configuraci√≥n de Backstage Pages

### Problema: Pages No Aparecen en Backstage

Las pages YAML que creamos son **templates de documentaci√≥n**, no p√°ginas funcionales de Backstage.

Para que aparezcan p√°ginas custom en Backstage, necesitas:

### Soluci√≥n 1: Usar Links en el Cat√°logo ‚úÖ (Implementado)

Los componentes del cat√°logo tienen links directos a cada servicio:

**Acceso**:
1. Ir a http://backstage.kind.local
2. Click en **"Catalog"**
3. Buscar componentes: `prometheus`, `grafana`, `argocd`
4. Click en cada componente
5. En la pesta√±a **"Overview"** ver los links

### Soluci√≥n 2: Crear Custom Pages (Requiere C√≥digo)

Para crear p√°ginas custom verdaderas necesitas:

#### 2.1 Modificar el c√≥digo fuente de Backstage

**Archivo**: `packages/app/src/App.tsx`
```tsx
import { MonitoringPage } from './components/monitoring';

const routes = (
  <FlatRoutes>
    {/* ... otras rutas ... */}
    <Route path="/monitoring" element={<MonitoringPage />} />
  </FlatRoutes>
);
```

#### 2.2 Crear componente de p√°gina

**Archivo**: `packages/app/src/components/monitoring/MonitoringPage.tsx`
```tsx
import React from 'react';
import { Page, Header, Content } from '@backstage/core-components';

export const MonitoringPage = () => {
  return (
    <Page themeId="tool">
      <Header title="Platform Monitoring" />
      <Content>
        <iframe
          src="http://prometheus.kind.local"
          width="100%"
          height="800px"
        />
      </Content>
    </Page>
  );
};
```

#### 2.3 Agregar al sidebar

**Archivo**: `packages/app/src/components/Root/Root.tsx`
```tsx
<SidebarItem icon={MonitoringIcon} to="monitoring" text="Monitoring" />
```

#### 2.4 Rebuild y redeploy
```bash
yarn build
docker build -t backstage-custom .
kind load docker-image backstage-custom
kubectl set image deployment/backstage backstage=backstage-custom -n backstage
```

### Soluci√≥n 3: Usar Dashboard Externo ‚úÖ (Recomendado para Laboratorio)

La forma m√°s simple es usar el dashboard que ya creamos:

**Archivo creado**: `templates/ba-platform-monitoring/config.yaml`

Este dashboard incluye:
- Links a todos los servicios
- Iframes embebidos
- Quick actions
- Documentaci√≥n

**Para usarlo**:
1. Los links ya est√°n en el cat√°logo de cada componente
2. Acceder directamente a las URLs:
   - http://prometheus.kind.local
   - http://grafana.kind.local
   - http://argocd.kind.local

---

## üìã Cat√°logo de Servicios

### Componentes en el Cat√°logo

| Nombre | Tipo | Sistema | Owner | Links |
|--------|------|---------|-------|-------|
| prometheus | service | monitoring | platform-engineering | UI, Targets, Alerts |
| grafana | service | monitoring | platform-engineering | UI, Dashboards |
| argocd | service | platform | platform-engineering | Console, Apps |
| kind-kubernetes-cluster | service | platform | platform-engineering | Resources |
| alertmanager | service | monitoring | platform-engineering | UI, Alerts |

### Systems

- **monitoring**: Monitoring & Observability
- **platform**: Platform Services

### C√≥mo Navegar el Cat√°logo

1. **Ir a Backstage**: http://backstage.kind.local
2. **Click en "Catalog"** en el sidebar
3. **Filtrar por**:
   - Type: Component
   - Owner: platform-engineering
   - System: monitoring o platform
4. **Click en un componente** para ver detalles
5. **En la pesta√±a "Overview"** encontrar√°s los links a los servicios

---

## üîë Acceso y Credenciales

### Obtener Credenciales

#### Grafana
```bash
# Usuario: admin
# Password:
kubectl get secret -n monitoring kube-prometheus-stack-grafana \
  -o jsonpath="{.data.admin-password}" | base64 -d && echo
```

#### ArgoCD
```bash
# Usuario: admin
# Password:
kubectl -n argocd get secret argocd-initial-admin-secret \
  -o jsonpath="{.data.password}" | base64 -d && echo
```

#### PostgreSQL (Backstage)
```bash
# Usuario: backstage
# Password:
kubectl get secret -n backstage psql-postgresql \
  -o jsonpath="{.data.postgres-password}" | base64 -d && echo
```

---

## üîß Troubleshooting

### Comandos √ötiles

```bash
# Ver todos los pods
kubectl get pods --all-namespaces

# Ver logs de Backstage
kubectl logs -f deployment/backstage -n backstage

# Reiniciar Backstage
kubectl rollout restart deployment/backstage -n backstage

# Ver eventos
kubectl get events -n backstage --sort-by='.lastTimestamp'

# Verificar ingresses
kubectl get ingress --all-namespaces

# Port-forward si ingress no funciona
kubectl port-forward svc/backstage 7007:80 -n backstage
kubectl port-forward svc/prometheus-prometheus 9090:9090 -n monitoring
kubectl port-forward svc/kube-prometheus-stack-grafana 3000:80 -n monitoring
```

### Problemas Comunes

#### Ingress 404/502
```bash
# Verificar /etc/hosts
cat /etc/hosts | grep kind.local

# Debe contener:
# 127.0.0.1 backstage.kind.local
# 127.0.0.1 prometheus.kind.local
# 127.0.0.1 grafana.kind.local
# 127.0.0.1 argocd.kind.local
# 127.0.0.1 alertmanager.kind.local
```

#### Pod no inicia
```bash
kubectl describe pod <pod-name> -n <namespace>
kubectl logs <pod-name> -n <namespace>
```

#### Cat√°logo no carga componentes
```bash
# Verificar ConfigMap
kubectl get configmap backstage-platform-catalog -n backstage

# Verificar montaje en deployment
kubectl describe deployment backstage -n backstage | grep -A 5 "Mounts:"

# Reiniciar
kubectl delete pod -n backstage -l app=backstage
```

---

## üìö Anexos

### Archivos Creados

#### Kubernetes Manifests
```
kubernetes/
‚îú‚îÄ‚îÄ namespace.yaml
‚îú‚îÄ‚îÄ secrets.yaml
‚îú‚îÄ‚îÄ configmap.yaml
‚îú‚îÄ‚îÄ rbac.yaml
‚îú‚îÄ‚îÄ simple-deployment.yaml
‚îú‚îÄ‚îÄ service.yaml
‚îú‚îÄ‚îÄ ingress.yaml
‚îú‚îÄ‚îÄ monitoring-ingresses.yaml
‚îî‚îÄ‚îÄ argocd-ingress.yaml
```

#### Helm Charts
```
helm-charts/
‚îî‚îÄ‚îÄ postgresql/
    ‚îú‚îÄ‚îÄ Chart.yaml
    ‚îú‚îÄ‚îÄ values.yaml
    ‚îî‚îÄ‚îÄ templates/
        ‚îú‚îÄ‚îÄ _helpers.tpl
        ‚îú‚îÄ‚îÄ deployment.yaml
        ‚îú‚îÄ‚îÄ pvc.yaml
        ‚îú‚îÄ‚îÄ secret.yaml
        ‚îî‚îÄ‚îÄ service.yaml
```

#### Catalog
```
backstage-catalog/
‚îî‚îÄ‚îÄ platform-services.yaml
```

#### Dashboard Templates
```
backstage-dashboard-templates/
‚îú‚îÄ‚îÄ catalog/
‚îÇ   ‚îî‚îÄ‚îÄ platform-services.yaml
‚îî‚îÄ‚îÄ templates/
    ‚îú‚îÄ‚îÄ ba-platform-monitoring/
    ‚îÇ   ‚îú‚îÄ‚îÄ catalog-info.yaml
    ‚îÇ   ‚îî‚îÄ‚îÄ config.yaml
    ‚îî‚îÄ‚îÄ pages/
        ‚îú‚îÄ‚îÄ prometheus/page.yaml
        ‚îú‚îÄ‚îÄ grafana/page.yaml
        ‚îú‚îÄ‚îÄ argocd/page.yaml
        ‚îî‚îÄ‚îÄ kubernetes/page.yaml
```

#### Documentation
```
docs/
‚îú‚îÄ‚îÄ PLATFORM_MONITORING_GUIDE.md
‚îú‚îÄ‚îÄ IMPLEMENTATION_SUMMARY.md
‚îú‚îÄ‚îÄ COMPLETE_IMPLEMENTATION_GUIDE.md (este archivo)
‚îî‚îÄ‚îÄ BACKSTAGE_PAGES_SETUP.md
```

---

## ‚úÖ Checklist de Validaci√≥n

- [x] Kind cluster funcionando
- [x] NGINX Ingress instalado
- [x] Prometheus desplegado y accesible
- [x] Grafana desplegado y accesible
- [x] ArgoCD desplegado y accesible
- [x] AlertManager desplegado y accesible
- [x] Backstage desplegado y accesible
- [x] PostgreSQL funcionando
- [x] Cat√°logo de servicios cargado
- [x] Ingresses configurados
- [x] DNS local configurado (/etc/hosts)
- [x] Resource quotas configurados
- [x] RBAC configurado
- [x] Documentaci√≥n completa

---

## üéØ Siguientes Pasos

### Para Acceder a las "Pages"

**Opci√≥n A - Usar Cat√°logo (M√°s Simple)** ‚úÖ
1. Ir a http://backstage.kind.local
2. Catalog ‚Üí Buscar componente
3. Click en los links de Overview

**Opci√≥n B - URLs Directas** ‚úÖ
1. http://prometheus.kind.local
2. http://grafana.kind.local
3. http://argocd.kind.local

**Opci√≥n C - Crear Custom Pages (Requiere Desarrollo)**
1. Modificar c√≥digo fuente de Backstage
2. Agregar rutas y componentes
3. Rebuild imagen
4. Redeploy

### Mejoras Futuras

- [ ] Implementar custom pages en c√≥digo
- [ ] Configurar alertas en Prometheus
- [ ] Crear dashboards custom en Grafana
- [ ] Automatizar backups
- [ ] Implementar logging con Loki
- [ ] Agregar tracing con Tempo

---

**üìß Soporte**: platform-engineering@ba.com
**üìñ Wiki**: http://backstage.kind.local/docs

---

*√öltima actualizaci√≥n: Octubre 6, 2025*
